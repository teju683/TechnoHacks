# -*- coding: utf-8 -*-
"""Image Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TKkQjmGHwjmvx0Y568HQtffHFDTVhgnE
"""

! wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz

!tar -xvf  /content/cifar-10-python.tar.gz

!pip install keras
!pip show keras

import numpy as np
import matplotlib.pyplot as plt
import os

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
import tensorflow.keras as k
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from six.moves import cPickle as pickle

def load_CIFAR_batch(filename):
    with open(filename, 'rb') as f:
        datadict = pickle.load(f, encoding='latin1')
        X = datadict['data']
        Y = datadict['labels']
        X = np.array(X)
        Y = np.array(Y)
        return X, Y

def load_CIFAR10(path):
    xs = []
    ys = []

    for number in range(1,6):
        file = os.path.join(path, 'data_batch_%d' %(number))
        X, Y = load_CIFAR_batch(file)
        xs.append(X)
        ys.append(Y)

    Xtrain = np.concatenate(xs)
    Ytrain = np.concatenate(ys)
    Xtest, Ytest = load_CIFAR_batch(os.path.join(path, 'test_batch'))
    return Xtrain, Ytrain, Xtest, Ytest

def get_CIFAR10_data():
    X_train, y_train, X_test, y_test = load_CIFAR10('/content/cifar-10-batches-py')
    x_train = X_train.astype('float32')
    x_test = X_test.astype('float32')
    x_train /= 255
    x_test /= 255
    return x_train, y_train, x_test, y_test

x_train, y_train, x_test, y_test = get_CIFAR10_data()

print('Train data shape  : ', x_train.shape)
print('Train labels shape: ', y_train.shape)
print('Test data shape   : ', x_test.shape)
print('Test labels shape : ', y_test.shape)

print('The training data contains %d images and %d labels' %(x_train.shape[0], y_train.shape[0]))
print('The testing  data contains %d images and %d labels' %(x_test.shape[0], y_test.shape[0]))

def rotate(imgs):
    for i in range(imgs.shape[0]):
        imgs[i] = np.rot90(imgs[i], k = -1)
    return imgs

def convert_into_images(data):
    data_shaped = data.reshape(data.shape[0], 3, 32, 32)
    data_swaped = np.swapaxes(data_shaped, 1, 3)
    data_rot = rotate(data_swaped)
    return data_rot

!pip install convert_images
!pip show convert_images

x_train = convert_into_images(x_train)
x_test = convert_into_images(x_test)

print('the training data has %d images of the shape : (%d, %d, %d)' % (x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3]))
print('the testing  data has %d images of the shape : (%d, %d, %d)' % (x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3]))

labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

def plot_sample_images(xdata, ydata):
    f, ax = plt.subplots(5, 5)
    for row in range(5):
        for col in range(5):
            idx = np.random.randint(0, xdata.shape[0])
            ax[row,col].imshow(xdata[idx])
            ax[row,col].set_title(labels[ydata[idx]], fontsize = 8)
            ax[row,col].get_xaxis().set_visible(False)
            ax[row,col].get_yaxis().set_visible(False)
    plt.subplots_adjust(hspace=0.4)
    plt.show()

plot_sample_images(x_train, y_train)

plot_sample_images(x_test, y_test)

classes, counts = np.unique(y_train, return_counts=True)
plt.barh(labels, counts)
plt.title('class distribution in training data')

classes, counts = np.unique(y_test, return_counts=True)
plt.barh(labels, counts)
plt.title('Class distribution in testing data')

categorical_y_train = to_categorical(y_train, 10)
categorical_y_test = to_categorical(y_test, 10)

model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.25))
model.add(Dense(10, activation='softmax'))

METRICS = ['accuracy',
    tf.keras.metrics.Precision(name='precision'),
    tf.keras.metrics.Recall(name='recall')
]

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)

model.summary()

data_generator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
train_generator = data_generator.flow(x_train, categorical_y_train, 32)
steps_per_epoch = x_train.shape[0] // 32

his = model.fit(train_generator, epochs=50, steps_per_epoch=steps_per_epoch, validation_data=(x_test, categorical_y_test), batch_size=32)

plt.figure(figsize=(8, 12))

plt.subplot(4, 2, 1)
plt.plot(his.history['loss'], label='Loss')
plt.plot(his.history['val_loss'], label='val_Loss')
plt.title('Loss Function Evolution')
plt.legend()

plt.subplot(4, 2, 2)
plt.plot(his.history['accuracy'], label='accuracy')
plt.plot(his.history['val_accuracy'], label='val_accuracy')
plt.title('Accuracy Function Evolution')
plt.legend()

plt.subplot(4, 2, 3)
plt.plot(his.history['precision'], label='precision')
plt.plot(his.history['val_precision'], label='val_precision')
plt.title('Precision Function Evolution')
plt.legend()

plt.subplot(4, 2, 4)
plt.plot(his.history['recall'], label='recall')
plt.plot(his.history['val_recall'], label='val_recall')
plt.title('Recall Function Evolution')
plt.legend()

evaluation = model.evaluate(x_test, categorical_y_test)
print(f'Test Accuracy : {evaluation[1] * 100:.2f}%')

y_pred = model.predict(x_test)
y_pred = np.argmax(y_pred, axis=1)
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)

fig, ax = plt.subplots(figsize=(10, 10))
disp = disp.plot(xticks_rotation='vertical', ax=ax,cmap='summer')

plt.show()

print('                      classification_report                      ')
print(classification_report(y_test, y_pred))

plt.figure(figsize=(2, 2))
plt.axis('off')
test_image = x_test[2000]
plt.imshow(test_image)
pred_class = np.argmax(model.predict(test_image.reshape(1, 32, 32, 3)))
print(f" the actual class of the image is : {labels[y_test[2000]]}")
print(f"the predicted class by the model is : {labels[pred_class]}")

from tensorflow.keras.models import load_model

model.save('cifar10_model.h5')